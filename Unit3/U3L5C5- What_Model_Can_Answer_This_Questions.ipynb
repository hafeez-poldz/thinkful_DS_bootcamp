{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: \n",
    "### For each, identify which supervised learning method(s) would be best for addressing that particular problem. Explain your reasoning and discuss your answers with your mentor.\n",
    "\n",
    "**Question 1:**\n",
    "Predict the running times of prospective Olympic sprinters using data from the last 20 Olympics. <br>\n",
    "**Answer:** \n",
    "Running time of sprinters is a continous variable. To predict it, I might create regression model using KNN Regression or Linear SVM.\n",
    "\n",
    "**Question 2:** \n",
    "You have more features (columns) than rows in your dataset. <br>\n",
    "**Answer:** \n",
    "If the number of observations is greater than the number of variables, there is no longer a unique least squares coefficients estimate. The variance is infinite. To fix this, I would apply linear regression with L2 regularization (Ridge Regression). With this method, the estimated coefficients are shrunken towards zero relatives to the least squares estimates. It will reduce the variance. Another way to deal with such kind of problem is Lasso Regression (L1 regularization) which will force some of the coefficient estimates to be exactly equal to zero. Also, principal component analysis can be useful to reduce the dimension.\n",
    "\n",
    "**Question 3.** \n",
    "Identify the most important characteristic predicting likelihood of being jailed before age 20. <br>\n",
    "**Answer:** \n",
    "For this task, the outcome variable will be binary (being jailed before 20 or not). This is a classification problem. As we need to identify the most important characteristic, then Gradient Boost classifier will be a good choice. It gives us an opportunity to get a measure of how important various features are by counting how many times a feature is used over the course of many decision trees. \n",
    "\n",
    "**Question 4:**\n",
    "Implement a filter to “highlight” emails that might be important to the recipient. <br>\n",
    "**Answer:** \n",
    "This is a classification problem. KNN Classifier, Logistic Regression (which acts as a classifier) or Support Vector Classifier could be good solutions.\n",
    "\n",
    "**Question 5:** \n",
    "You have 1000+ features. <br>\n",
    "**Answer:**\n",
    "PCA and L1 regularization are ways to reduce the number of features.\n",
    "\n",
    "**Question 6:** \n",
    "Predict whether someone who adds items to their cart on a website will purchase the items.<br>\n",
    "**Answer:** \n",
    "As outcome variable is categorical, I would use Random Forest Classifier, Naive Bayes or Logistic Regression\n",
    "\n",
    "**Question 7:**\n",
    "Your dataset dimensions are 982400 x 500 <br>\n",
    "**Answer:**\n",
    "To reduce the number of features, I would apply a PCA or Lasso technique.\n",
    "\n",
    "**Questionn 8:** \n",
    "Identify faces in an image.<br>\n",
    "**Answer:**\n",
    "Target variable is continuous. So SVM regression can be helpful.\n",
    "\n",
    "**Question 9:**\n",
    "Predict which of three flavors of ice cream will be most popular with boys vs girls.<br>\n",
    "**Answer:**\n",
    "This is a classification problem. KNN, SVM, Random Forest or Naive Bayes are good to apply.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
